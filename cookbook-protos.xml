<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.3//EN" "http://www.oasis-open.org/docbook/xml/4.3/docbookx.dtd">     

<chapter id="cb-proto">
  <title>Protocols</title>

  <section id="cb-proto-dcap">
    <title>dCap options mover and client options</title>
    <partauthors>Patrick Fuhrmann, Tigran Mkrtchyan</partauthors>
    <para>
      dCap is the native random access I/O protocol for files within dCache.
      In additition to the usual data transfer mechanisms, it supports all necessary
      file metadata and name space manipulation operations.
    </para>
    <para>
     In order to optimize I/O transferrates and memory consumption dCap allows
     to configure parameters within the client and the server. e.g:
	<itemizedlist>
	  <listitem>
	    <para>
	      TCP Socket send and receive buffer sizes.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      I/O buffers sizes.
	    </para>
	  </listitem>
	</itemizedlist>
    </para>
    <section>
      <title>TCP send/recv buffer sizes from the servers point of view</title>
      <para>
         There are two parameters per I/O direction, determining the actual
         TCP send/recv buffer size used for each transfer. Those values can
         be set within the <filename>config/pool.batch</filename> file on the pool nodes.
	<itemizedlist>
	  <listitem>
	    <para>
	      <option>defaultSend/RecvBufferSize</option> : this value is used if the dCap client
              doesn't try to set this value. The default value for this parameter
              is 256K Bytes.
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      <option>maxSend/RecvBufferSize</option> : this value is the maximum value,
              the mover is allowed to use. It's used if either the
              <option>defaultSend/RecvBufferSize</option> is larger or the client asks
              for a larger value. The default value for this parameter is 1MBytes.
	    </para>
	  </listitem>
	</itemizedlist>
      </para>
      <para>
        On the server side, the max/defaultSend/RecvBuffer value can either be set in the
        <filename>config/pool.batch</filename> file or in the <filename>config/*.poollist</filename> files. 
      </para>
      <para>
        Using the batch context :
        <screen>
set context dCap3-maxSendBufferSize <option>value in bytes</option>
set context dCap3-maxRecvBufferSize <option>value in bytes</option>
set context dCap3-defaultSendBufferSize <option>value in bytes</option>
set context dCap3-defaultRecvBufferSize <option>value in bytes</option>
        </screen>
        Or it may specified in the create ... command line
        <screen>
  create diskCacheV111.pools.MultiProtocolPool2 ${0} \
  "!MoverMap \
  ${1} \
  -defaultSendBufferSize=<option>value in bytes</option> \
  *** \
  -${2} -${3} -${4} -${5} -${6} -${7} -${8} \
"
         </screen>
         The most appropriate way to specify those values on the server side
         is certainly to add the corresponding entry in the 
         <filename>config/...poollist</filename>. The entry would look like
         <screen>
dcache30_1  /dcache/pool  sticky=allowed maxSendBufferSize=<option>value in bytes</option> tag.hostname=dcache30 ***
         </screen>
      </para>
      <para>
      Please note the different ways of using the '=' and the '-' sign in the different
      alternatives.
      </para>
    </section>
    <section>
      <title>TCP send/recv buffer sizes from the dCap clients point of view</title>
      <para>
      For a full list of dCap library API calls and dccp options, please refer to
      to <literal>http://www.dcache.org/manuals/libdcap.shtml</literal> and 
      <literal>http://www.dcache.org/manuals/dccp.shtml</literal> respectively.
      To set the local and remote TCP buffer send and receive buffers either use
      the API call <literal>dc_setTCPSend/ReceiveBuffer(int size)</literal> or the
      <option>-r SIZE -s SIZE</option> dccp options. In both cases the value is
      transferred to the remote mover which tries to set the corresponding values.
      Please not the the server protects itself by having a maximum size for those
      values which it doesn't exceed. Please check the section 'TCP send/recv buffer 
      sizes from the servers point of view' to learn how to change those values.
      </para>
    </section>
  </section>  
  <section id="cb-proto-dcap-open">
    <title>Specifying dCap open timeouts</title>
    <partauthors>Patrick Fuhrmann</partauthors>
    <para>
      In cases where dccp/dcap requests a file which is still on tertiary storage,
      the user resp. the administrator might what to limit the time, dccp/dCap
      waits in the open call until the file has been fetched from backend storage.
      This, so called <literal>openTimeout</literal>, can be specified on the server
      or on the client. In all cases the <literal>-keepAlive</literal> must be specified
      with an appropriate number of seconds on the cell create command in the 
      door batch files. The following mechanisms are available to specify open timeouts :
      <table tabstyle="cellattributes">
        <title>Open Timeout mechanisms</title>

        <tgroup cols="4" align="left">
          <colspec colnum="1" colname="Precedence" colwidth="70"/>
          <colspec colnum="2" colname="Mechanism" colwidth="70"/>
          <colspec colnum="3" colname="Key Name" colwidth="120"/>
          <colspec colnum="4" colname="Example"/>
          <thead>
            <row>
              <entry>
                Precedence
              </entry>
              <entry>
                Mechanism
              </entry>
              <entry>
                Key Name
              </entry>
              <entry>
                Example
              </entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>Lowest</entry>
              <entry>context</entry>
              <entry>dCap-openTimeout</entry>
              <entry>set context dCap-openTimeout 200</entry>
            </row>
            <row>
              <entry>...</entry>
              <entry>context</entry>
              <entry>openTimeout</entry>
              <entry>set context openTimeout 200</entry>
            </row>
            <row>
              <entry>...</entry>
              <entry>cell create command line</entry>
              <entry>openTimeout</entry>
              <entry>-openTimeout=200</entry>
            </row>
            <row>
              <entry>Highest</entry>
              <entry>dccp command line</entry>
              <entry>-o</entry>
              <entry>dccp -o200 SOURCE DESTINATION</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
   
<screen>
#
#    dCap    D o o r (create command line example)
#
create dmg.cells.services.login.LoginManager DCap-2 \
            "${specialDCapPort} \
             diskCacheV111.doors.DCapDoor \
             -export \
             *** \
             -keepAlive=60 \
             -openTimeout=300 \
             *** \
             -loginBroker=LoginBroker"
</screen>
<screen>
#
#    dCap    D o o r (context example)
#
set context dCap-openTimeout 200
#
create dmg.cells.services.login.LoginManager DCap-2 \
            "${specialDCapPort} \
             diskCacheV111.doors.DCapDoor \
             -export \
             *** \
             -keepAlive=60 \
             *** \
             -loginBroker=LoginBroker"
</screen>
<screen>
#
dccp -o200 /pnfs/desy.de/data/dteam/private/myfile /dev/null</screen>
    </para>
    <para>
    If the openTimeout expires while a read transfer is already active,
    this transfer will be interrupted, but it will automatically resume
    because the client can't destinguish between a network failure and
    a timeout. So the timeout disturbes the read but it will finally
    succeed. This is different for write. If a write is interrupted by
    a timeout in the middle of a transfer, dccp will stuck. (This is not
    a feature and needs further investigation).
    </para>
  </section>
  
  <section id="cb-proto-dcap-ext">
    <title>Using the dCap protocol for strict file checking</title>
    <partauthors>Patrick Fuhrmann, Tigran Mkrtchyan</partauthors>
    <para>
       The dcap protocol allows to check whether a dataset is on tape
       only or has a copy on a dCache disk. The dCap library API
       call is <literal> int dc_check(const char *path, const char *location)</literal>
       and the dccp options are <literal>-t -1 -P</literal>.
       For a full list of dCap library API calls and dccp options, please refer to
       to <literal>http://www.dcache.org/manuals/libdcap.shtml</literal> and 
       <literal>http://www.dcache.org/manuals/dccp.shtml</literal> respectively.
       Using a standard dCache installation those calls will return a guess
       on the file location only. It is neither checked
       whether the file is really on that pool or if the pool is up. To get a strict
       checking a dCap door has to be started with a special (-check=strict) option.
<screen>
#
#    dCap    D o o r
#
create dmg.cells.services.login.LoginManager DCap-strict \
            "${specialDCapPort} \
             diskCacheV111.doors.DCapDoor \
             -check=strict \
             -export \
             -prot=telnet -localOk \
             -maxLogin=1500 \
             -brokerUpdateTime=120 \
             -protocolFamily=dcap \
             -loginBroker=LoginBroker"
</screen>
    This door will do a precise checking (-check=strict). To get the dCap lib and
    dccp to use this door only, the <literal>DCACHE_DOOR</literal>
    environment variable has to be set to <option>doorHost:specialDCapPort</option>
    in the shell, dccp is going to be used.
    In the following example we assume that the <literal>specialDCapPort</literal> has
    been set to <literal>23126</literal> :
    <screen>
   export DCACHE_DOOR=dcachedoorhost:23126
   dccp -P -t -1 /pnfs/domain.tv/data/cms/users/waste.txt </screen>
    </para>
    <para>
    If <literal>dccp</literal> returns <literal>File is not cached</literal> and this
    dCache instance is connected to an HSM, the file is no longer on one of the dCache
    pools but is assumed to have a copy within the HSM. If the dccp returns this message and
    no HSM is attached, the file is either on a pool which is currently down or the file
    is lost.
    </para>
  </section>
  
  
  <section id="cb-proto-dcap-passive">
    <title>Passive dCap</title>

    <partauthors>Tigran, Patrick</partauthors>

    <para>
      The dCap protocol, similiar to FTP, uses a control channel to request a transfer which 
      is subsequently done through data channels. Per default, the data channel
      is initiated by the server, connecting to an open port in the client library.
      This is commonly known as active transfer.
      Starting with dCache 1.7.0 the dCap protocol supports passive transfer mode as well,
      which consequently means that the client connects to the server
      pool to initiate the data channel. This is essential to support dCap clients running
      behind firewalls and within private networks.
    </para>
    <section>
    <title>Preparing the server for dCap passive transfer</title>
    <para>
    The port(s), the server pools should listens on, can be specified by the
    org.dcache.net.tcp.portrange variable, as part of the 'java_options' directive in the
    <filename>config/dCacheSetup</filename> configuration file. A range has to be
    given if pools are split amoung multiple JVMs. E.g:
<programlisting>
java_options="-server ... -Dorg.dcache.net.tcp.portrange=33115:33145"</programlisting>
    </para>
    </section>
    <section>
    <title>Switching the dCap library resp. dccp to PASSIVE</title>
    <para>
    <screen>Remark : The commonly used expression 'passive' is seen from the server perspective and
actually means 'server passive'. From the client perspective this is of course 'active'.
Both means that the client connects to the server to establish the data connection. 
This mode is supported by the server
starting with 1.7.0 and dccp with 1-2-40 (included in 1.7.0)</screen>
    </para>
    <para>
    The following dCap Api call  switches all subsequent dc_open calls to server-passive mode
    if this mode is supported by the corresponding door. (dCache Version >= 1.7.0).
<programlisting>
<command>void dc_setClientActive()</command></programlisting>
    </para>
    <para>
    The environment variable <command>DCACHE_CLIENT_ACTIVE</command>  switches
    the dCap library to server-passive. This is true for dCap, dCap preload and dccp.
    </para>
    <para>
    dccp, switches to server-passive when issuing the <command>-A</command> command line option.
    </para>
    </section>
  </section>
  <section id="cb-proto-firewall">
    <title>Access to SRM and GridFTP server from behind a firewall</title>

    <partauthors>Timur Perelmutov, Mathias de Riese</partauthors>

    <para>
      This describes firewall issues from the clients
      perspective. <xref linkend="cb-net-firewall"/> discusses the
      server side.
    </para>

    <para>
      When files are transferred in gridftp active mode from gridftp
      server to the gridftp client, server establishes data channel(s)
      by connecting to the client. In this case client creates a tcp
      socket, bound to some particular address on the client host, and
      sends the client host ip and port to the server. If the client
      host is running a firewall, firewall might refuse server's
      connection to the client's listening socket.  Common solution to
      this problem is establishing a range of ports on the client's
      host that are allowed to be connected from Internet by changing
      firewall rules.Once the port range is defined the client can be
      directed to use one of the ports from the port ranges when
      creating listening tcp sockets.
    </para>

    <section>
      <title>Access with srmcp</title>

      <para>
	If you are using srmcp as a client you need to do the
	following:

	<itemizedlist>
	  <listitem>
	    <para>
	      create a directory $HOME/.globus if it does not exist
	    </para>
	  </listitem>
	  <listitem>
	    <para>
	      create and/or edit a file
	      $HOME/.globus/cog.properties by appending a new
	      line reading

<programlisting>tcp.port.range=<replaceable>min</replaceable>,<replaceable>max</replaceable></programlisting>

	      where <replaceable>min</replaceable> and
	      <replaceable>max</replaceable> are the lower and upper
	      bounds of the port range.
	    </para>
	  </listitem>
	</itemizedlist>

      </para>

      <para>
	With the latest srmcp release you can use the <option>globus_tcp_port_range</option> option:

<screen><userprompt/><command>srmcp</command> -globus_tcp_port_range=<replaceable>minValue</replaceable>:<replaceable>maxValue</replaceable> ...</screen>


	A range of ports open for tcp connections is specified as a
	pair of positive integers separated by ":". This is not set by
	default.
      </para>

    </section>

    <section>
      <title>Access with globus-url-copy</title>

      <para>
	If you are transferring files from gridftp server using
	<command>globus-url-copy</command>, you need to define an
	environment variable <varname>GLOBUS_TCP_PORT_RANGE</varname>,
	in the same shell in which <command>globus-url-copy</command>
	will be executed.
      </para>

      <para>
	In sh/bash you do that by invoking the following command:

<screen><userprompt/>export GLOBUS_TCP_PORT_RANGE="<replaceable>min</replaceable>,<replaceable>max</replaceable>"</screen>

	in csh/tcsh you invoke:

<screen><userprompt/>setenv GLOBUS_TCP_PORT_RANGE "<replaceable>min</replaceable>,<replaceable>max</replaceable>"</screen>

	here <replaceable>min</replaceable> and
	<replaceable>max</replaceable> are again the lower and upper
	bounds of the port range
      </para>
      
    </section>
      
  </section>
  
  <section id="cb-proto-dis-dcap">
    <title>Disableing unauthenticated dCap via SRM</title>
    
    <!-- 
    <para>
      NOCLUE: Meta-intro? Where to put this? A more general section about
      protocolls in Configuration?
    </para> 
    -->

    <para>
      In some cases SRM transfers fail because they are tried via
      the plain dCap protocol (URL starts with
      <literal>dcap://</literal>). Since plain dCap is
      unauthenticated, the dCache server will have no information
      about the user trying to access the system. While the transfer
      will succeed if the UNIX file permissions allow access to
      anybody (e.g. mode 777), it will fail otherwise. 
    </para>
    
    <para>
      Usually all doors are registered in SRM as potential access
      points for dCache. During a protocol negotiation the SRM
      chooses one of the available doors. You can force srmcp to use
      the gsidcap protocol (<option>-protocol=gsidcap</option>) or
      you can unregister plain, unauthenticated dCap from known
      protocols: From the file
      <filename>config/door.batch</filename> remove
      <option>-loginBroker=LoginBroker</option> and restart dcap
      door with
      
<screen><rootprompt/>jobs/door stop
<rootprompt/>jobs/door -logfile=<replaceable>dCacheLocation</replaceable>/log/door.log start</screen>

    </para>
    
  </section>

  <unfinished>
    Maybe, this section should go into some kind of user
    documentation part of the book.
  </unfinished>
  
</chapter>
