<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.3//EN"
                         "http://www.oasis-open.org/docbook/xml/4.3/docbookx.dtd" [
<!ENTITY % sharedents SYSTEM "shared-entities.xml" >
%sharedents;
]>

<chapter id="cb-tuning">

  <title>Advanced Tuning</title>

  <para>
    The use cases described in this chapter are only relevant for
    large-scale &dcache; instances which require special tuning
    according to a longer experience with client behaviour.
  </para>

  <section id="cb-adv-multi-mover-queues">
    <title>Multiple Queues for Movers in each Pool</title>

    <section id="cb-adv-multi-mover-queues-d">
      <title>Description</title>

      <para>
        Client requests to a &dcache; system may have rather diverse
        behaviour. Sometimes it is possible to classify them into
        several typical usage patterns. An example are the following
        two concurrent usage patterns:
      </para>

      <informalexample>

	<para>
	  Data is copied with a high transfer rate to the &dcache;
	  system from an external source. This is done via the
	  &gridftp; protocol. At the same time batch jobs on a local
	  farm process data. Since they only need a small part of each
	  file, they use the &dcap; protocol via the &dcap; library
	  and seek to the position in the file they are interested in,
	  read a few bytes, do a few hours of calculations, and
	  finally read some more data.
	</para>

      <para>
        As long as the number of active requests does not exceed the
        maximum number of allowed active requests, the two types of
        requests are processed concurrently. The &gridftp; transfers
        complete at a high rate while the processing jobs take hours
        to finish. This maximum number of allowed requests is set with
        <xref linkend="cmd-mover_set_max_active"/> and
        should be tuned according to capabilities of the pool host.
      </para>
      
      <para>
        However, if requests are queued, the slow processing jobs
        might clog up the queue and not let the fast &gridftp; request
        through, even though the pool just sits there waiting for the
        processing jobs to request more data. While this could be
        temporarily remedied by setting the maximum active requests to
        a higher value, then in turn &gridftp; request would put a
        very high load on the pool host.
      </para>
      </informalexample>

      <para>
        The above example is pretty realistic: As a rule of thumb,
        &gridftp; requests are fastest, &dcap; requests with the
        &prog-dccp; program are a little slower and &dcap; requests
        with the &dcap; library are very slow. However, the usage
        patterns might be different at other sites and also might
        change over time.
      </para>

    </section>

    <section id="cb-adv-multi-mover-queues-s">
      <title>Solution</title>

      <para>
        Use separate queues for the movers, depending on the door
        initiating them. This easily allows for a separation of
        requests of separate protocols.
        (Transfers
        from and to a <glossterm linkend="gl-tape_backend">tape
        backend</glossterm> and <glossterm
        linkend="gl-p2p">pool-to-pool transfers</glossterm> are
        handled by separate queues, one for each of these transfers.)
      </para>

      <para>
        A finer grained queue selection mechanism based on, e.g. the
        &ip; address of the client or the file which has been
        requested, is not possible with this mechanism. However, the
        <glossterm linkend="gl-pm-comp-psu">pool selection unit
        (PSU)</glossterm> may provide a separation onto separate pools
        using those criteria.
      </para>

      <para>
        In the above example, two separate queues for fast &gridftp;
        transfers and slow &dcap; library access would solve the
        problem. The maximum number of active movers for the &gridftp;
        queue should be set to a lower value compared to the &dcap;
        queue since the fast &gridftp; transfers will put a high load
        on the system while the &dcap; requests will be mostly idle.
      </para>

    </section>

    <section id="cb-adv-multi-mover-queues-c">
      <title>Configuration</title>

      <para>
	For a multi mover queue setup, the pools have to be told to
	start several queues and the doors have to be configured to
	use one of these. It makes sense to create the same queues on
	all pools. This is done by the following change to the file
	<filename>&path-ode-ed;/dcache.conf</filename>:
      </para>
      <programlisting>pool.queues=queueA,queueB</programlisting>

      <para>
	Each door may be configured to use a particular mover
	queue. The pool, selected for this request, does not depend on
	the selected mover queue. So a request may go to a pool which
	does not have the particular mover queue configured and will
	consequently end up in the default mover queue of that pool.
      </para>
      <programlisting>ftp.mover.queue=queueA
dcap.mover.queue=queueB</programlisting>
      <para>
        All requests send from this kind of door will ask to be
        scheduled to the given mover queue. The selection of the pool
        is not affected.
      </para>

      <para>
	The doors are configured to use a particular mover queue as in
	the following example:
      </para>

      <informalexample>
	<para>
	  Create the queues <literal>queueA</literal> and
	  <literal>queueB</literal>, where <literal>queueA</literal>
	  shall be the queue for the &gridftp; transfers and
	  <literal>queueB</literal> for &dcap;.
	</para>

      <programlisting>pool.queues=queueA,queueB
ftp.mover.queue=queueA
dcap.mover.queue=queueB</programlisting>
      </informalexample>

      <para>
	If the pools should not all have the same queues you can
	define queues for pools in the layout file. Here you might as
	well define that a specific door is using a specific queue.
      </para>
      <informalexample>
	<para>
	 In this example <literal>queueC</literal>is defined for
	 <literal>pool1</literal> and <literal>queueD</literal> is
	 defined for <literal>pool2</literal>. The &gridftp; door
	 running in the domain <literal>myDoors</literal> is using the
	 queue <literal>queueB</literal>.
	</para>

	<programlisting>[myPools]
[myPools/pool1]
pool.queues=queueC
[myPools/pool2]
pool.queues=queueD

[myDoors]
[myDoors/dcap]
dcap.mover.queue=queueC
[myDoors/ftp]
ftp.authn.protocol = gsi
ftp.mover.queue=queueD</programlisting>
      </informalexample>

      <para>
	There is always a default queue called
	<literal>regular</literal>. Transfers not requesting a
	particular mover queue or requesting a mover queue not
	existing on the selected pool, are handled by the
	<literal>regular</literal> queue.
      </para>

      <para>
	The pool cell commands <xref linkend="cmd-mover_ls"/> and
	<xref linkend="cmd-mover_set_max_active"/> have a
	<option>-queue</option> option to select the mover queue to
	operate on. Without this option, <xref
	linkend="cmd-mover_set_max_active"/> will act on the default
	queue while <xref linkend="cmd-mover_ls"/> will list all
	active and waiting client transfer requests.
      </para>

      <para>
        For the &dcap; protocol, it is possible to allow the client to
        choose another queue name than the one defined in the file
        <filename>dcache.conf</filename>. To achieve this
        the property <varname>dcap.authz.mover-queue-overwrite</varname> needs to
        be set to <literal>allowed</literal>.
      </para>

      <informalexample>
	<para>
	  Create the queues <literal>queueA</literal> and
	  <literal>queue_dccp</literal>, where <literal>queueA</literal>
	  shall be the queue for &dcap;.
	</para>
	<programlisting>pool.queues=queueA,queue_dccp
dcap.mover.queue=queueA
dcap.authz.mover-queue-overwrite=allowed</programlisting>


      <para>
	With the &prog-dccp; command the queue can now be specified as
	follows:
      </para>

      <screen>&prompt-user; <userinput>dccp -X-io-queue=queue_dccp <replaceable>source</replaceable> <replaceable>destination</replaceable></userinput></screen>

      </informalexample>
      <para>
        Since &prog-dccp; requests may be quite different from other
        requests with the &dcap; protocol, this feature may be used to
        use separate queues for &prog-dccp; requests and other &dcap;
        library requests. Therefore, the &prog-dccp; command may be
        changed in future releases to request a special
        <command>dccp</command>-queue by default.
      </para>

    </section>
  <section id="cb-adv-multi-mover-queues-t">
    <title>Tunable Properties for Multiple Queues</title>

      <informaltable tabstyle="small">

	<tgroup cols="3" align="center">
	  <colspec colnum="1" colname="Property" colwidth="*" align="left"/>
	  <colspec colnum="2" colname="Default Value" colwidth="*"/>
	  <colspec colnum="3" colname="Description" colwidth="2*" align="left"/>
	  <thead>
	    <row>
	      <entry align="center">Property</entry>
	      <entry>Default Value</entry>
	      <entry align="center">Description</entry>
	    </row>
	  </thead>
          <tbody>
            <row>
	      <entry>pool.queues</entry>
	      <entry>&no-default;</entry>
	      <entry> I/O queue name</entry>
	    </row>
            <row>
	      <entry>dcap.mover.queue</entry>
	      <entry>&no-default;</entry>
	      <entry>Insecure &dcap; I/O queue name</entry>
	    </row>
	    <row>
	      <entry>dcap.mover.queue</entry>
	      <entry>&no-default;</entry>
	      <entry>&gsidcap; I/O queue name</entry>
	    </row>
            <row>
	      <entry>dcap.authz.mover-queue-overwrite</entry>
	      <entry>denied</entry>
	      <entry>Controls whether an application is allowed to overwrite a queue name</entry>
	    </row>
            <row>
	      <entry>dcap.authz.mover-queue-overwrite</entry>
	      <entry>denied</entry>
	      <entry>Controls whether an application is allowed to overwrite a queue name</entry>
	    </row>
            <row>
	      <entry>dcap.authz.mover-queue-overwrite</entry>
	      <entry>denied</entry>
	      <entry>Controls whether an application is allowed to overwrite a queue name</entry>
	    </row>
            <row>
	      <entry>ftp.mover.queue</entry>
	      <entry>&no-default;</entry>
	      <entry>&gsiftp; I/O queue name</entry>
	    </row>
            <row>
	      <entry>nfs.mover.queue</entry>
	      <entry>&no-default;</entry>
	      <entry>&nfs; I/O queue name</entry>
	    </row>
            <row>
	      <entry>transfermanagers.mover.queue</entry>
	      <entry>&no-default;</entry>
	      <entry>queue used for SRM third-party transfers (i.e. the srmCopy command)</entry>
	    </row>
            <row>
	      <entry>webdav.mover.queue</entry>
	      <entry>&no-default;</entry>
	      <entry>&webdav; and &http; I/O queue name</entry>
	    </row>
            <row>
	      <entry>xrootd.mover.queue</entry>
	      <entry>&no-default;</entry>
	      <entry>&xrootd; I/O queue name</entry>
	    </row>
          </tbody>
        </tgroup>
      </informaltable>
      <!-- Dirty hack to introduce a potential page-break -->
      <para/>

    </section>
  </section>


  <section id="cb-tuning-parameters">
    <title>Tunable Properties</title>

    <section id="cb-tuning-parameters-dcap">
      <title>&dcap;</title>

      <table tabstyle="small">
	<title>Property Overview</title>

	<tgroup cols="3" align="center">
	  <colspec colnum="1" colname="Property" colwidth="*" align="left"/>
	  <colspec colnum="2" colname="Default Value" colwidth="*"/>
	  <colspec colnum="3" colname="Description" colwidth="2*" align="left"/>
	  <thead>
	    <row>
	      <entry align="center">Property</entry>
	      <entry>Default Value</entry>
	      <entry align="center">Description</entry>
	    </row>
	  </thead>
          <tbody>
	    <row>
	      <entry>dcap.mover.queue</entry>
	      <entry>&no-default;</entry>
	      <entry>&gsidcap; I/O queue name</entry>
	    </row>
            <row>
	      <entry>dcap.mover.queue</entry>
	      <entry>&no-default;</entry>
	      <entry>Insecure &dcap; I/O queue name</entry>
	    </row>
            <row>
	      <entry>dcap.authz.mover-queue-overwrite</entry>
	      <entry>denied</entry>
	      <entry>Is application allowed to overwrite queue name?</entry>
	    </row>
            <row>
	      <entry>dcap.authz.mover-queue-overwrite</entry>
	      <entry>denied</entry>
	      <entry>Is application allowed to overwrite queue name?</entry>
	    </row>
          </tbody>
        </tgroup>
      </table>

      <!-- Dirty hack to introduce a potential page-break -->
      <para/>

    </section>

    <section id="cb-tuning-parameters-gsiftp">
      <title>&gridftp;</title>

      <table tabstyle="small">
	<title>Property Overview</title>

	<tgroup cols="3" align="center">
          <colspec colnum="1" colname="Property" colwidth="*" align="left"/>
          <colspec colnum="2" colname="Default Value" colwidth="*"/>
          <colspec colnum="3" colname="Description" colwidth="2*" align="left"/>
	  <thead>
             <row>
	       <entry align="center">Property</entry>
	       <entry>Default Value</entry>
	       <entry align="center">Description</entry>
	     </row>
          </thead>
          <tbody>
            <row>
	      <entry>ftp.net.port.gsi</entry>
	      <entry>2811</entry>
	      <entry>&gsiftp; port listen port</entry>
	    </row>
            <row>
	      <entry>spaceReservation</entry>
	      <entry>&false;</entry>
	      <entry>Use the space reservation service</entry>
	    </row>
            <row>
	      <entry>spaceReservationStrict</entry>
	      <entry>&false;</entry>
	      <entry>Use the space reservation service</entry>
	    </row>
            <row>
	      <entry>ftp.performance-marker-period</entry>
	      <entry>180</entry>
	      <entry>Performance markers in seconds</entry>
	    </row>
            <row>
	      <entry>gplazmaPolicy</entry>
	      <entry>${ourHomeDir}/etc/dcachesrm-gplazma.policy</entry>
	      <entry>Location of the gPlazma Policy File</entry>
	    </row>        
            <row>
	      <entry>ftp.service.poolmanager.timeout</entry>
	      <entry>5400</entry>
	      <entry>Pool Manager timeout in seconds</entry>
	    </row>
            <row>
	      <entry>ftp.service.pool.timeout</entry>
	      <entry>600</entry>
	      <entry>Pool timeout in seconds</entry>
	    </row>
            <row>
	      <entry>ftp.service.pnfsmanager.timeout</entry>
	      <entry>300</entry>
	      <entry>Pnfs timeout in seconds</entry>
	    </row>
            <row>
	      <entry>ftp.limits.retries</entry>
	      <entry>80</entry>
	      <entry>Number of PUT/GET retries</entry>
	    </row>
            <row>
	      <entry>ftp.limits.streams-per-client</entry>
	      <entry>10</entry>
	      <entry>Number of parallel streams per &ftp; PUT/GET</entry>
	    </row>
            <row>
	      <entry>ftp.enable.delete-on-failure</entry>
	      <entry>&true;</entry>
	      <entry>Delete file on connection closed</entry>
	    </row>
            <row>
	      <entry>ftp.limits.clients</entry>
	      <entry>100</entry>
	      <entry>Maximum number of concurrently logged in users</entry>
	    </row>
            <row>
	      <entry>ftp.net.internal</entry>
	      <entry>&no-default;</entry>
	      <entry>In case of two interfaces</entry>
	    </row>
            <row>
	      <entry>ftp.net.port-range</entry>
	      <entry>20000:25000</entry>
	      <entry>The client data port range</entry>
	    </row>
            <row>
	      <entry>gplazma.kpwd.file</entry>
	      <entry><filename>${ourHomeDir}/etc/dcache.kpwd</filename></entry>
	      <entry>Legacy authorization</entry>
	    </row>
          </tbody>
        </tgroup>
      </table>

      <!-- Dirty hack to introduce a potential page-break -->
      <para/>

    </section>

    <section id="cb-tuning-parameters-srm">
      <title>&srm;</title>

      <table tabstyle="small">
        <title>Property Overview</title>

        <tgroup cols="3" align="center">
          <colspec colnum="1" colname="Property" colwidth="3*" align="left"/>
          <colspec colnum="2" colname="Default Value" colwidth="2*"/>
          <colspec colnum="3" colname="Description" colwidth="3*" align="left"/>
	  <thead>
	    <row>
	      <entry align="center">Property</entry>
	      <entry>Default Value</entry>
	      <entry align="center">Description</entry>
	    </row>
          </thead>

	  <tbody>
	    <row>
	      <entry>srm.net.port</entry>
	      <entry>8443</entry>
	      <entry>srm.net.port</entry>
	    </row>
	    <row>
	      <entry>srm.db.host</entry>
	      <entry><systemitem class="systemname">localhost</systemitem></entry>
	      <entry>srm.db.host</entry>
	    </row>
	    <row>
	      <entry>srm.limits.external-copy-script.timeout</entry>
	      <entry>3600</entry>
	      <entry>srm.limits.external-copy-script.timeout</entry>
	    </row>
	    <row>
	      <entry>srmVacuum</entry>
	      <entry>&true;</entry>
	      <entry>srmVacuum</entry>
	    </row>
	    <row>
	      <entry>srmVacuumPeriod</entry>
	      <entry>21600</entry>
	      <entry>srmVacuumPeriod</entry>
	    </row>
	    <row>
	      <entry>srmProxiesDirectory</entry>
	      <entry><filename class="directory">/tmp</filename></entry>
	      <entry>srmProxiesDirectory</entry>
	    </row>
	    <row>
	      <entry>srm.limits.transfer-buffer.size</entry>
	      <entry>1048576</entry>
	      <entry>srm.limits.transfer-buffer.size</entry>
	    </row>
	    <row>
	      <entry>srm.limits.transfer-tcp-buffer.size</entry>
	      <entry>1048576</entry>
	      <entry>srm.limits.transfer-tcp-buffer.size</entry>
	    </row>
	    <row>
	      <entry>srm.enable.external-copy-script.debug</entry>
	      <entry>&true;</entry>
	      <entry>srm.enable.external-copy-script.debug</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.scheduler.thread.queue.size</entry>
	      <entry>1000</entry>\
	      <entry>srm.limits.request.scheduler.thread.queue.size</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.scheduler.thread.pool.size</entry>
	      <entry>100</entry>
	      <entry>srm.limits.request.scheduler.thread.pool.size</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.scheduler.waiting.max</entry>
	      <entry>1000</entry>
	      <entry>srm.limits.request.scheduler.waiting.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.scheduler.ready-queue.size</entry>
	      <entry>1000</entry>
	      <entry>srm.limits.request.scheduler.ready-queue.size</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.scheduler.ready.max</entry>
	      <entry>100</entry>
	      <entry>srm.limits.request.scheduler.ready.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.scheduler.retries.max</entry>
	      <entry>10</entry>
	      <entry>srm.limits.request.scheduler.retries.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.scheduler.retry-timeout</entry>
	      <entry>60000</entry>
	      <entry>srm.limits.request.scheduler.retry-timeout</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.scheduler.same-owner-running.max</entry>
	      <entry>10</entry>
	      <entry>srm.limits.request.scheduler.same-owner-running.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.put.scheduler.thread.queue.size</entry>
	      <entry>1000</entry>
	      <entry>srm.limits.request.put.scheduler.thread.queue.size</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.put.scheduler.thread.pool.size</entry>
	      <entry>100</entry>
	      <entry>srm.limits.request.put.scheduler.thread.pool.size</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.put.scheduler.waiting.max</entry>
	      <entry>1000</entry>
	      <entry>srm.limits.request.put.scheduler.waiting.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.put.scheduler.ready-queue.size</entry>
	      <entry>1000</entry>
	      <entry>srm.limits.request.put.scheduler.ready-queue.size</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.put.scheduler.ready.max</entry>
	      <entry>100</entry>
	      <entry>srm.limits.request.put.scheduler.ready.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.put.scheduler.retries.max</entry>
	      <entry>10</entry>
	      <entry>srm.limits.request.put.scheduler.retries.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.put.scheduler.retry-timeout</entry>
	      <entry>60000</entry>
	      <entry>srm.limits.request.put.scheduler.retry-timeout</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.put.scheduler.same-owner-running.max</entry>
	      <entry>10</entry>
	      <entry>srm.limits.request.put.scheduler.same-owner-running.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.copy.scheduler.thread.queue.size</entry>
	      <entry>1000</entry>
	      <entry>srm.limits.request.copy.scheduler.thread.queue.size</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.copy.scheduler.thread.pool.size</entry>
	      <entry>100</entry>
	      <entry>srm.limits.request.copy.scheduler.thread.pool.size</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.copy.scheduler.waiting.max</entry>
	      <entry>1000</entry>
	      <entry>srm.limits.request.copy.scheduler.waiting.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.copy.scheduler.retries.max</entry>
	      <entry>30</entry>
	      <entry>srm.limits.request.copy.scheduler.retries.max</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.copy.scheduler.retry-timeout</entry>
	      <entry>60000</entry>
	      <entry>srm.limits.request.copy.scheduler.retry-timeout</entry>
	    </row>
	    <row>
	      <entry>srm.limits.request.copy.scheduler.same-owner-running.max</entry>
	      <entry>10</entry>
	      <entry>srm.limits.request.copy.scheduler.same-owner-running.max</entry>
	    </row>
          </tbody>
        </tgroup>
      </table>
    </section>
  </section>


</chapter>
